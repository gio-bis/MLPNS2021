{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CART.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtzECkkQ6Ec0Ef27APJ84S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gio-bis/MLPNS2021/blob/main/Appunti%20Lezioni/CART.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFq4xGXc_-PY"
      },
      "source": [
        "Un single tree model è una sequenza di decisioni, ciascuna delle quali è binaria. I single tree sono però problematici perché hanno high variance (variabilità del risultato). Siccome per ogni variabile continua c'è un'infinita possibilità di fare uno split, questo introduce un problema computazionale: non si può risolvere il problema esplorando interamente la likelihood surface per ottenere una posterior che sia veramente l'ottimizzazione del problema. Siccome non si può fare una ricerca computazionale completa, si deve introdurre un random guess per inizializzare scelte che rendono il problema computazionalmente possibile. Quindi non si può fare una ricerca esaustiva del modllo e la scelta è basata su ottimizzazione locale, non globale. Questi 2 problemi rendono i single trees praticamente inutilizzabili.\n",
        "La soluzione è far correre il modello più volte e vedere tra tutti i risultati diversi qual è il più comune. Si parla di ensemble methods. Ci sono 2 scelte:\n",
        "\n",
        "1) Random Forests (stochastic variation, alberi in parallelo, indipendenti l'un l'altro, usano un subset di osservabili/features)\n",
        "\n",
        "2) Gradient Boosted Trees (progressive variation, usano tutto lo spazio delle features, ma aggiunge pesi alle features che imparano dagli alberi precedenti; l'ultimo albero è quello che ha la predizione finale)\n",
        "\n",
        "\n",
        "Gli alberi possono essere usati anche per fare regression, pensandoli come classifier con classi molto piccole.\n",
        "\n",
        "Gli alberi possono essere usati se abbiamo sia variabili numeriche che categoriche. \n",
        "\n",
        "Rispetto a tutti gli altri metodi non ci dobbiamo preoccupare troppo della covarianza tra le features.\n",
        "\n",
        "Si deve normalizzare prima di dividere in train e test set in modo che essi siano normalizzati sulla base delle stesse proprietà statistiche. \n",
        "\n",
        "Se il test set è troppo piccolo non si ha un risultato statisticamente robusto su quale sia veramente l'accuratezza nella predizione, d'altra parte se non si hanno abbastanza dati per il training set è un problema perché si può ottenere un risultato non accurato. L'unica soluzione se il dataset non è troppo grande da ottenere sia un training che un test set di dimensioni ragionevoli è fare multiple cross validation, cioè fare la divisione tra train e test un sacco di volte.\n",
        "\n",
        "Panda ha una utility function che permette di visualizzare la codipendenza dei dati (pd.plotting.scatter_matrix()). Se lo spazio non ha covariance questi plot sono tutti rotondi, se lo spazio ha covariance questi diventano righe, forme strane. La diagonale permette di visualizzare diverse cose (se si visualizzasse la correlazione vedremmo delle righe, cosa inutile). Un esempio è l'istogramma di ciascuna variabile. \n",
        "\n",
        "Quando usiamo random forest e gradient boosted tree non è strettamente necessario scalare i dati perché la caratteristica principale dei tree models rispetto a tutti gli altri modelli è che trattano una feature alla volta, pertanto non è necessario che le features siano comparabili perché la scelta che faccio a ogni nodo dell'albero è esclusivamente legata a quella variabile che è automaticamente scalata rispetto a se stessa. Per lo stesso motivo non mi preoccupo della covariance. \n",
        "\n",
        "\n",
        "Se uso i trees non è un problema se le variabili non sono gaussiane. \n",
        "\n",
        "Lo score riportato da un classifier è l'accuratezza della predizione, cioè la frazione di labels predette correttamente. \n",
        "\n",
        "Si può valutare l'accuratezza del modello in maniera più sofisticata rispetto allo score, che non mi dice cosa ho sbagliato. False positive e False negative non sono la stessa cosa, la loro importanza dipende dalle conseguenze del risultato. \n",
        "Il bilancio di false positive e false negative è mostrato dalla confusion matrix. Il fatto di avere pochi off diagonal elements e che essi sono più o meno bilanciati mi dice che ho un risultato decente. Un modello con score bilanciati tra train e test set è superiore perché se ho overfitting, nonostante lo score sul test sia simile a quello di un modello in cui non ho overfitting, niente mi vieta che utilizzando come test set dati diversi io non possa ottenere un'accuratezza peggiore. \n",
        "\n",
        "\n",
        "Nel caso del regressor non ho uno score, ma l'accuratezza è data da qualcosa relazionato al chi-square o L2.\n",
        "\n",
        "SOlitamente i gradient boosted tree performano meglio rispetto ai random forest models, ma sono più difficili da interpretare.\n",
        "\n",
        "\n",
        "Il modo più comune e preferito per valutare la performance di un classifier probabilistico è la ROC (Receiver Operator Characteristic Curve) e la AOC (area all'interno della curva). Sull'asse x ho i false positive, sull'asse y i true positive. La curva mi dice qual è la balance tra false e true positive sulla base della threshold nella probabilità della classificazione. Random forest produce una classificazione probabilistica, cioè se metà degli alberi mi dice una cosa e metà degli alberi un'altra, l'interpretazione frequentista mi dirà che avrò il 50% di avere una certa predizione. A questo punto devo decidere qual è la threshold sulla confidenza (voglio il 90% degli alberi che mi danno una predizione oppure meno?). In funzione di questa threshold posso mettere un punto per ciascuna threshold su questo plot. \n",
        "Se avessi un modello ideale vorrei avere =% false positive e 100% true positive. Però siccome in quel punto non ci sarò mai, il punto che scelgo dipende da qual è il mio interesse scientifico. \n",
        "\n",
        "La performance del modello è misurata dall'area sottesa alla curva AOC"
      ]
    }
  ]
}