{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised Learnign.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGcO0gbW9UpxO0y5zsfkRj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gio-bis/MLPNS2021/blob/main/Appunti%20Lezioni/Unsupervised_Learnign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sePg7lZ7I2Le"
      },
      "source": [
        "Problemi dell'one-hot encoding:\n",
        "\n",
        "1) aumenta il numero di variabili\n",
        "2) variabili correlate, non indipendenti\n",
        "\n",
        "\n",
        "\\\\\n",
        "-dredging- \n",
        "\n",
        "-nested models-\n",
        "\n",
        "\\\\\n",
        "**Correlation/covariance matrix**\n",
        "Se i dati non sono correlati è una matrice con 1 sulla diagonale e 0 nel resto\n",
        "\n",
        "**Whitening**\n",
        "SIgnifica manipolare i dati in modo da poter rimuovere la correlazione. Si può fare se la matrice è diagonalizzabile (invertibile, ...). Si usa il pacchetto ZCA. In molti casi non funziona. Se non si fa questo (o non si è fortunatati e non si riesce a fare) si devono scalare i dati. Si deve standardizzare (sottrarre la media e dividere per la standard deviation). Il centro dei dati è 0 e la standard deviation è 1 (una sfera)\n",
        "\n",
        "\n",
        "\\\n",
        "##CLUSTERING\n",
        "\n",
        "### K-means\n",
        "It's non deterministic. Dipende dal punto iniziale (random or not)\n",
        "Funziona solo se si può definire una media. Funziona quindi solo per variabili numeriche, non categoriche.\n",
        "Richiede di sapere all'inizio il numero di cluster. Se ho più cluster ho maggiore compattezza dei cluster. Elbow method per determinare il numero di cluster. Lavora solo con distanze euclidee.\n",
        "\n",
        "### Hierarchical clustering\n",
        "Vantaggio: non si deve scegliere a priori il numero di cluster. In questo caso bisogna definire anche una distanza tra gruppi\n",
        "- Agglomerative: parto da gruppi di 1 elemento e devo calcolare la distanza tra ogni coppia di punti per unire poi gruppi vicini\n",
        "\n",
        "- Divisive: analogo ma parto con 1 gruppo e divido\n",
        "\n",
        "A differenza di K-Means è deterministico\n",
        "Tempo computazionale lungo se aumento il numero di dati\n",
        "\n",
        "\n",
        "###DBSCAN\n",
        "Permette di individuare anomalie e outliers perché unisce in cluster punti che hanno una certa densità di punti attorno"
      ]
    }
  ]
}